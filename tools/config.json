{
  "openai_call": {
    "prompt": "- self.openai_call(prompt, ?temperature=0.4, ?max_tokens=200) -> str: runs an arbitrary LLM completion. I must use f-strings to pass values and context;\nI must use this ONLY when I need to handle LARGE texts and nlp processes with large data. To handle small nlp it's just I myself write as I'd write normally. Using all knowledge that I've learned from the Corpus of my training;\n",
    "enabled": true
  },
  "execution_agent": {
    "prompt": "- self.execution_agent(task:str) -> str; I must use this if I need to run arbitrary code based on a dinamic value (i.e a openai response, a memory call or even another execution_agent);\n",
    "enabled": true
  },
  "count_tokens": {
    "prompt": "- self.count_tokens(text:str) -> int; to count the ammount of tokens of a given string, I need to use this when handling with large files/data, and when I don't know the size of the data;",
    "enabled": true
  },
  "process_large_text": {
    "prompt": "- self.process_large_text(text:str, instruction:str, split_text:function, max_output_length=1000:int)->str, to process large texts with openai_call, it splits the text in chunks of max size of max_output_length given the specific split_text function (I must create a function to each case, sometimes it can be useful to just split using the chars count, but sometimes I might use some specific function to parse css, html, programming languages...)\n\n\nsplit_text function example:\ndef split_text(text, max_length):\n    # Split text into chunks of length at most max_length\n    chunks = []\n    while len(text) > 0:\n        chunk = text[:max_length]\n        text = text[max_length:]\n        chunks.append(chunk)\n    return chunks\n",
    "enabled": true
  },
  "get_serp_query": {
    "prompt": "- self.get_serp_query_result(query: str, n: int) -> list of lists on format [['snippet', 'link'], ['snippet', 'link']], return the n most relevant results of a given query using SerpAPI (GoogleSearch);",
    "enabled": false
  },
  "memory_agent": {
    "prompt": "- self.memory_agent(caller:str, content:str, goal:goal) - str or True if there's no return string. This agent can handle memory I/O and can create severals types of memories. Avoid using this;\n",
    "enabled": false
  }
}